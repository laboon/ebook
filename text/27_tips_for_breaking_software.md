# Breaking Software

Thus far, we have focused on how to develop test plans, but there has been little discussion of what to test, outside of ensuring that the software meets the requirements.  While this is not the worst approach to testing software, it leaves out important aspects in regards to verification, especially in checking for more obscure edge cases.

The reason one tests is to find defects; in order to find defects, you may have to venture a bit from the happy path, where everybody enters data in the format you like, systems have infinite memory and CPU, and your zero-latency networks are always connected.  You'll have to traverse through the dark woods where people try to enter "`FORTY-SEVEN`" instead of "`47`", where the program runs out of memory midway through a computation, where a horror movie villain stands poised above the Ethernet cable with a sharpened hatchet.

Maybe not that last one. However, you will have to think of ways to test for the operation of a system when things aren't quite perfect.  Consider this chapter a way of priming your testing brain for how to cause failures and find the cracks in the software under test.

## Errors To Look For

1. __Logic Errors:__ A logic error is an error in the logic of the program.  The developer understood what needed to be done, but in the process of converting the system from its description to its implementation, something went wrong.  This could be as simple as accidentally replacing a greater-than (`>`) with a less-than (`<`), or as complicated as an intricate interaction between numerous variables.

    In order to check for logic errors, you should ensure that the expected result occurs for a variety of inputs.  Boundaries---explicit and implicit---are often a rich vein to be mined for defects.  Try other kinds of interesting input as well, such as special characters, exceedingly long strings, and improperly-formatted data.  Input that comes from other systems or users will often send strange or incorrect data.  It's good to know what happens when your system receives it.

    For complex output (e.g., generating a large web page from a template), it may not be feasible to check the output directly.  However, you can check that there are valid properties of the output, and that those properties are expected.  For example, you can check that the generated page data can be parsed and that it displays and shows data correctly.  You can also look at the data from a higher abstraction level---instead of checking that there is an HTML `<strong>` tag around every occurrence of the word "cat" on a page, it may be easier to look at the page, search for cat, and check that each time it is displayed, it is in bold.

2. __Off-By-One Errors:__ Although technically a logic error, these are so common that they will be addressed separately.  An off-by-one error is when a program does something wrong because a value is off by just one unit.  This is the reason that there was a focus on determining boundary values in a previous chapter---boundary values are a focused way of looking for off-by-one errors.  Why are these so common?  Let's imagine a very simple method which returns whether or not a person is a minor or not:

    ```java
    public boolean isMinor(int personAge) {
        if (personAge <= 18) {
            return true;
        } else {
            return false;
        }
    }
    ```

    Did you spot the error?  At least in the United States at the time of this writing, you are no longer considered a minor once you reach 18.  By using `<=` instead of `<`, the method will return that the person is still a minor when they turn 18.  This minor mistake can happen in all sorts of ways---thinking that an array is 1-indexed instead of 0-indexed, confusing a "greater than or equal to" sign with "greater than", using `++i` when you should `i++`, etc.  These are also often less visible than other errors, since they will only show up for specific values.

    When testing, check the boundary values and you are likely to run across some off-by-one errors.

3. __Rounding and Floating Point Errors:__ Computer systems often use floating-point variables to represent decimal numbers such as 1.1.  These are often much more efficient than using arbitrary-precision or rational values, but this efficiency comes with a cost---loss of precision.  For example, assume that the system under test is using IEEE 754 single-precision 32-bit floating point values.  Entering 1.1 as a value does not mean that the value is stored as 1.1.  Instead, it's stored as 1.10000002384185791015625, because there are a literally infinite number of decimal numbers, and they all need to be stored in 32 bits.  Whenever you try to map an infinite amount of values to a finite space, there's going to have to be multiple values that share the same representation.  If you remember your discrete math, this is the Pigeonhole Principle in operation.  That value just happened to be the closest possible value to 1.1.  Mapping multiple values to the same representation is essentially saying that values will be rounded.

    "That's fine," you may think, "that's such a small amount of difference between the actual value and the represented value.  I can't imagine it would make a difference."  What happens when you multiply it by another floating point number, though?  The difference may be magnified.  And then multiply it by another floating point, and another... soon you may be dealing with values that are not at all close to what they are supposed to be!  Although a gradual drifting of values is not guaranteed to happen, since some represented values may be higher and some lower than the actual value, it is certainly possible.

    This is one of the reasons that there is a `Currency` data type in many programming languages; imagine a bank getting these kinds of calculations wrong.  Using floating-point values could cost them vast amounts of money.  And it could be even worse, no imagination necessary: read up on the Patriot Missile Defense Failure of 1991.  Accumulated floating point errors resulted in an American base's failure to detect an incoming Scud missile during the Gulf War, causing 28 deaths and around 100 injuries.

    In other cases, there may also be a deliberate loss of precision due to rounding, or to a program taking the ceiling or floor of a number.  For example, at some point a program may have to convert a decimal value to an integer, and the programmer has many choices in how to do this.  The conversion could always round down (e.g., 4.8 becomes 4, dropping everything to the right of the decimal point), it could always round up (e.g., converting 4.3 to 5), or it could use the rounding we all learned in elementary school, rounding up to if the number if 4.5 or greater and rounding down otherwise.  Which is the correct path to take?  It depends on the program and the expected output, and it's easy to get wrong.

    In order to check for rounding and floating point errors, try testing with different decimal values as input.  Ensure that the final output does, in fact, match the expected output within the range of error.  If the input data is going to interact with other data, check what happens when there is a large amount of data.  These kinds of errors will often be compounded, and thus easier to detect, when there are large amounts of data.

4. __Integration Errors:__ When errors exist at the interface between two different parts of a system, this is known as an integration error.  Interfaces can be as small as class boundaries, up to package boundaries, or interprocess boundaries, all the way up to boundaries between large, multi-computer systems.  Because interfaces are often where there are splits between teams or individuals working on different parts of a system, they are a target-rich environment for defects.  Teams tend to communicate better with other members of a team; after all, they are working on similar pieces of the system and will often get rapid feedback whenever there is a problem when working on their particular subsystem.  When interacting with other teams, miscommunication is more possible, and that creates opportunities for double-checking that the system is working correctly and that the assumptions that were made are correct.  Even if there is a well-defined interface specification, there are opportunities for misunderstandings of the specification or errors in implementing it.

    As a tester, a focus on testing how systems integrate will pay great dividends.  Ensuring that systems interoperate correctly is often difficult for developers to do, since they tend to be focused on the specific aspect of the software they are working on, as opposed to having a holistic view of the system.

5. __Errors of Assumption:__ It is, for all intents and purposes, impossible to completely define most systems using requirements.  If you were to define a system that precisely, you would have basically written the program.  Therefore, developers will often make assumptions about how the program is supposed to behave.  However, these assumptions may not be in line with what the customer requires, or how other systems expect the system to act.  Some common examples to check for include:

    1. How should the system display errors?
    2. How should data be displayed or otherwise output?
    3. Are there any requirements on formatting of files?
    4. What systems need to be supported?
    5. What other systems will this interact with?
    6. What sort of interfaces will be necessary?
    7. What kind of user experience and user interface is expected?
    8. How will the system be accessed?  By whom?
    9. What kind of terminology, acronyms, etc. are used?
    10. What are valid ranges or limits for data?
    11. How will data be input?  In what formats?

    If you assume that all weight input comes in as pounds, what happens when someone else assumes that it is in kilograms?  Was an assumption made that output is in ASCII, but some data is input in Unicode, thus causing data to be lost upon display?  Did a software engineer write a program that uses a command-line interface when the customer actually wanted a GUI?  Are output files written using CSV (comma-separated values) when downstream users expect them to be tab-separated?  All of these are assumptions in the development process that can lead to defects when the system is used.

    There also may be common requirements for a given domain, of which the software developers are not aware.  After all, software developers tend to be software developers, not subject matter experts on the domain of the software they are writing.  That is not always the case, of course, but often enough there will be a disconnect between the knowledge of the person developing the system and the eventual customer.

    As a tester of software, you can and should help to bridge that gap.  Understanding what the customer requires, as well as how developers are writing the software, can allow you to see discrepancies and know what to look for when you are developing test plans.  It also can help you prioritize and strategize when you are determining what features and edge cases to check.  For example, if you know that a particular kind of file that your system operates on is rarely over 50 kilobytes when your program is used, you can focus on testing small files instead of the edge cases inherent in dealing with extremely large files.

6. __Missing Data Errors:__ Whenever data comes in from an external source to the program (e.g., from a CSV file, or an API endpoint, or from direct user input on the terminal), there exists the chance that necessary data will be missing.  This may be as simple as a user accidentally hitting Enter when asked for input, or as complex as a missing attribute somewhere deep within a large JSON response.  In all cases, though, the system should deal with it appropriately.  Always assume that anything external may or may not send you all of the data that you need.

    What to do when data is missing is going to vary by program and by domain.  In some cases, your program can safely ignore it; in others, it should be flagged or logged, or the user alerted; in rare instances, the correct thing to do is shut down the entire system.  However, you should know how a system is supposed to respond to missing data, and determine that the system actually performs that way when it encounters it.

7. __Bad Data Errors:__ Even more problematic than Missing Data Errors are Bad Data Errors.  While there is only one item to check for a given attribute when looking at Missing Data Errors, there are almost infinitely many possible ways for data to be "bad".  This data could be generated internally, but the most likely cause of bad data is data coming from an external system which has different assumptions, uses a different format, has been corrupted or modified in some way, etc.

    1. __Data is too long:__ Perhaps the system can only handle up to a certain amount of data.  What happens if the input data is longer than that?
    2. __Data is too short:__ On the other hand, what if the system operates strangely with very small amounts of data?  This won't be as common as problems with data being too long, but it is often a cause of inefficiency (e.g., a system always allocating a megabyte for every input by default, even if it's only a few bytes long).
    3. __Data is formatted incorrectly:__ What happens if your program expects comma-delimited data, and it receives tab-delimited data?  What happens if your program expects a JSON string, but it receives XML?
    4. __Data is out of range:__ What happens if your software is asked for the 593rd State of the United States?  What happens if the temperature is listed as -500 degrees Celsius (which is below absolute zero, and thus impossible in this universe)?
    5. __Data has been corrupted:__ Are there any safeguards when accepting data that checks that data is legitimate and has not been modified?  Although data corruption is less of a problem than it used to be, there could still be errors such as someone opening a file in a text editor on a different operating system, causing all linefeed characters to be converted to an unexpected character.
    6. __Data is not consistent:__ What happens if input data contradicts itself?  For example, if you are receiving data and it has two listings for user ID 723, one with the name "John Doe" and one with the name "Jane Doe"?  Do you know what the expected behavior should be in this situation?
    7. __Data is unparseable:__ What happens if you receive data that cannot be parsed, because it missing a closing `>` or `)`, or has a circular reference?  Does the system give an appropriate error message, or even know that it is stuck in an infinite loop?

    Tracking down bad data problems can be difficult, since there are so many ways that things can go wrong, and oftentimes only a very particular configuration of bad data will cause a problem.  While it's certainly possible to write test data that is problematic in different ways, a more efficient way is to use __fuzz testing__---sending in randomly generated data (which may or may not conform to the expected input in different ways) and ensuring that the system still operates correctly.  See the chapter on Stochastic Testing for more information on fuzz testing.

8. __Display Errors:__ While a system may compute the correct value, it may be displayed incorrectly.  This may be a problem when a number or string is too large to be displayed in full (e.g., displaying the result of `1 / 3`), and so characters are cut off.  In other cases, there may be no cut-off, so that the display of a value causes problems by overwriting or otherwise distorting other aspects of a display.  If you are displaying values on a chart, an outlier on the X or Y axes may either not be displayed, or be displayed well off the chart, causing issues for other aspects of the display.  Graphics may be displayed incorrectly, or the wrong bitmap or color may be used.  Certain characters printed to a display may cause the terminal to freeze, or a bell to beep, or cause other issues with the display.  Improperly escaped HTML may cause your rendered web page to no longer appear.

    Whenever data is displayed, check not only that the value was computed properly, but also that is being displayed properly.  By sending in data that contains odd characters, or extremely large or small values, or that is missing some normally-expected value, you can ensure that all the time spent determining the right value to display is actually seen by the user.

9. __Injection Errors:__ A subset of Bad Data Errors, Injection Errors are when executable code or other instructions are passed in to a program.  If a program can be tricked into executing these instructions, the consequences can be dire, including loss or corruption of data, unauthorized access to a system, or simply causing the system to crash.

    An especially common issue is not dealing with escapes or odd characters properly.  An escape code which is not caught by the interface that the data is entered in may be used by another subsystem that does recognize it, or vice-versa.  Characters may be used for different purposes by different subsystems or language.  For example, Java strings can have null characters inside of them, whereas a null character indicates "end of string" for C strings.

    In order to test for these, determine what happens when various kinds of code are passed in to the program.  This doesn't have to be Java (or whatever language the system itself is written in).  A web application might execute JavaScript code on visitors' browsers.  Many systems use SQL for database updates and queries, and arbitrary SQL code can change or delete data.  The injected code could be assembly at the end of a long input---a trick often used to take advantage of a buffer overflow vulnerability (see the chapter on Security Testing for more information).  Checking all of these potential issues involves testing a wide variety of inputs, and there are adversaries who stand to gain personally from you missing a single point of entry for their malicious programs.

10. __Network Errors:__ Although computers are becoming more and more networked all the time, network connectivity is not yet ubiquitous or trouble-free.  The system should continue to work even if network connectivity is temporarily lost.  Some systems, of course, require network connectivity to work (running ssh or a web browser would be rather boring if you could not connect to any other systems), but they certainly should not crash or freeze without it.

    Perhaps the most dramatic example of testing against network errors is the "hatchet test" (alluded to above), in which a tester takes a hatchet and chops the cable connecting the system to the network.  This can be simulated, with slightly less chance of injury, by unplugging the cable or turning off the wireless connectivity in the middle of the program's operation.

    Loss of connectivity is not the only possible issue that a network-enabled program could encounter.  You may also wish to check what happens when there is extremely high latency or extremely low bandwidth.  Often, a program may assume that as long as there is connectivity, that it must be good connectivity, and the system will become unusable when the connection exists but the connectivity is very poor.  Another scenario to check is when network connectivity is spotty (connecting and disconnecting frequently), which may cause problems which are not seen when there is one long interruption of service.  A network connection with a high rate of packet loss may provide a good test, especially if you are using UDP or another connectionless protocol.  For a real test, you may want to add corruption to the line.  In all of these situations, and other network problems, the system should degrade gracefully instead of failing hard.

11. __Disk I/O Errors:__ Data inside your program lives in a nice, little, prepared world.  Data outside your program is vicious and uncontrolled, red in tooth and claw, following no law but Murphy's.  If you're reading a file off a disk, perhaps the file you are trying to read doesn't exist.  Perhaps it does exist, but it's of the wrong format.  Perhaps it's of the right format, but it's corrupted.  Perhaps you're trying to write to it, but it's read-only.  Perhaps another user has opened it in the meantime.  Perhaps it's in a directory to which your user does not have access.  Perhaps you had access to that directory when the program started, but not now.  Perhaps the file exists, but is empty.  Perhaps the file is several hundred megabytes and you only expected it to be a few kilobytes.  The list of things goes on and on.

    You should be checking that if your system needs to access the disk, it is prepared for these eventualities.  One possibility is to have a special testing subdirectory filled with all sorts of odd files, and whenever a new function would read a file, I would run it against these.  These odd files would hit all of the variations mentioned above, as well as domain-specific oddities such as files whose internal structure was self-referential, or contained missing data, etc.

12. __Interface Errors:__ Systems often need to communicate with other systems, and they will need some sort of interface to do so.  This interface may be more or less well-defined, from simply accepting text as input and providing text as output (such as with most Unix utilities such as `more` or `grep`) up to complex binary formats.  However, this interface does need to be defined at some level, and there exists the possibility that the definition is specified ambiguously, or different parts of the definition contradict each other, or each side of the interface team had different assumptions when creating it (see Errors of Assumption, above).  There also exists the possibility that it was just programmed incorrectly!

    These interfaces do not have to be inter-process or inter-computer.  They can be as low-level as an interface between two classes.  The interface to a method is usually easy to understand; in Java, for instance, it's trivial to see what the following method accepts as arguments and what it outputs, even without comments:

    ```java
    public boolean greaterThanTen(int a, int b) {
        if ((a + b) > 10) {
            return true;
        } else {
            return false;
        }
    }
    ```

    In the previous instance, you can see that the method accepts two integers, and returns a Boolean.  It's also relatively easy to determine what the method does, even without comments.  Although it's always possible to write obfuscated code (intentionally or unintentionally), and rely on side effects and global variables, the average programmer's brain tends to be decent at understanding things at the method level.  As soon you go up to the class level, it can be more difficult to tell how things interoperate, and why.  No longer are you looking at the language itself, focusing on keywords like `for`, `if`, and `return` that are as familiar as your childhood blankie.  Instead, you are seeing a sort of "meta-language" of the class, which will be new to you.  You're working at a higher level of abstraction, and it gets even worse as you move up to higher and higher levels.  The cure is to define and design the interfaces well, but what may make sense to one person is likely to cause another to throw their hands up in despair.  Interfaces also tend to demarcate the line between developers or teams of developers.  Thus, they also mark a fertile ground for misunderstanding, and where there is misunderstanding, there too are defects.

    When testing, you should spend time exploring the interfaces in the system.  These are areas where communication may have broken down, or where people on differing sides made different assumptions.  What happens when you try to pass in unexpected values?  What happens if an expected value is not sent in, or more values are sent in than expected?  What happens if data is out of range, or too large?

13. __Null Pointer Errors:__ You may be lucky enough to be working in a language in which the concept of a null pointer does not exist, but if you are programming in Java you are probably more familiar with these than you care to admit.  Any time that an object might be null, there needs to be an explicit check to ensure that it's not before trying to access it.  In a talk on the history of the concept of null, Franklin Chen noted that in languages like Java, any object is always of two possible types---the object itself, or a null version of itself.  You can't assume that if you have an `Integer` object, for example, that it's actually an `Integer`; it might be a null object masquerading as integer.  For an in-depth look at the "billion-dollar problem" of null pointers, you can [watch Franklin Chen's talk](http://franklinchen.com/blog/2012/09/06/my-pittsburgh-ruby-talk-nil/).

    This can be relatively easy to look for if you are doing white-box testing and can see the code itself.  If you're performing black-box testing, though, you can still think of cases where an object may not exist.  What happens when you try to search for an object in a database that doesn't exist?  What happens when you don't enter anything in a text box?  What happens when you give an invalid ID?  For many programs, the behavior necessary to operate under these conditions must be explicitly programmed.  Any time that a common behavior must be checked for explicitly, there is a chance that the programmer forgets to do it or does it incorrectly.

14. __Distributed System Errors:__ Testing a system which runs concurrently on multiple servers comes with its own set of issues.  In many cases, there is not a "truth" copy of data (one place where the data is expected to always be the correct data, as opposed to places which contain "copies" which may be out-of-date or incorrect).  Not only must you worry about testing it with different hardware and software setups, but also check different network topologies and different combinations of hardware and software setups.  Different levels of bandwidth and latency may cause defects to manifest themselves.  Times and timestamps may differ from one system to another, multiple people may be modifying the same data from different machines, different machines may have different concepts of the current state of the data, etc.  There are numerous situations where determining what the expected behavior should be is difficult, if not altogether impossible.

    When testing a distributed system, you should spend time checking that systems are synchronizing correctly; data should be coherent, at least eventually.  Ensure that the system works whenever different aspects of the system change, and especially when individual systems break down (as they almost certainly will at some point---the more machines you have running your code, the more likely at least one will have a failure).  Read Peter Deutsch's [_Fallacies of Distributed Computing_](https://blogs.oracle.com/jag/resource/Fallacies.html) (don't worry, it's a very quick read) and think of what assumptions you and the developers of the system have made... and then break those assumptions.

15. __Configuration Errors:__ There are two different ways that configuration errors can manifest themselves.  First, the administrators of a system can configure a software system in many different ways.  For example, when setting up a Rails application, there are numerous configuration options in various YAML files that you can set.  Many applications have configuration settings, command-line switches, or other ways of modifying how they operate, and they sometimes override or interact with each other in strange ways.

    Secondly, if a system is reachable online, the users of a system may have set up their personal computers in many different ways.  There are many web browsers, for instance, from full-featured ones released by major companies and organizations, to small text-based browsers.  These browsers have various levels of compatibility with standards.  Users will be running them on different operating systems, with different hardware, and different software and plug-ins.  Some users keep JavaScript enabled all the time, others don't; some users block third-party applications or advertisements; some users don't display images; some users send a "Do Not Track" request and some don't; the list goes on and on.  There always exists the possibility that a problem lies with a specific configuration.

    Will your system perform properly under every possible configuration that users use to access it (e.g., with different browsers, with JavaScript disabled, with images disabled, etc.)?  Does it give proper information on the problem if it is configured incorrectly?  Does it provide sensible defaults (or warn the user, depending on the requirements and domain) if a configuration value is missing or invalid?  Do certain settings override others in ways that are non-obvious, or cause problems when set in certain combinations?

16. __Accessibility Errors:__ Oftentimes, systems will work properly when used by a user using a standard configuration, but not when a user is using a non-standard input or output device.  These are often necessary for users who cannot access a system using the standard keyboard-mouse-monitor input/output setup; for example, blind users who use a braille terminal for reading output from their computer.  If your software does not work correctly with these systems, then people who depend on them may have no other way to use your software.

    Be sure that you provide multiple methods of input and output, or at a bare minimum can at least accept and output raw text of some sort.  Not all users can use a mouse, or can view graphics.  Don't assume that the setup that you have will work for everyone who uses the software.

## The List Goes On and On

This chapter is not a complete list of how to break programs and find defects.  It's not even a fairly comprehensive list.  The fact is, computers do exactly what you tell them to do, and one of the challenges of writing software is telling the computer exactly what do under all sorts of circumstances.  While many of these circumstances are relatively common across programs (such as dealing with missing files or network connectivity), many other errors will be specific to the domain you are working in, or the program you are writing.  As a tester, you will need to keep an open mind and constantly be thinking of ways in which defects can manifest themselves in the particular program under test.

As you are doing so, remember to keep in mind that you are not the user.  You, as a tester of the software, are going to be familiar with the system under test---if not at first, then eventually.  In many cases, you will be more technically competent in general than the person using the software.  The users are not going to use the software the same way as you do, and things which seem obvious to you will certainly not be obvious to them.  It is important to keep in mind the kind of mistakes that the users will make, the kind of input the users will provide, and the kind of output that the user will expect to see.
